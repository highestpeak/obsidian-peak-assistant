import { LLMStreamEvent, LLMUsage, LLMRequestMessage, StreamTriggerName, ToolResultOutput, ToolEvent } from '@/core/providers/types';
import { toReActThoughtPromptMessages, generateToolCallId, convertMessagesToText } from '@/core/providers/adapter/ai-sdk-adapter';
import { contentReaderTool } from '@/service/tools/content-reader';
import {
    inspectNoteContextTool,
    graphTraversalTool,
    findPathTool,
    findKeyNodesTool,
    findOrphansTool,
    searchByDimensionsTool,
    exploreFolderTool,
    recentChangesWholeVaultTool,
    localSearchWholeVaultTool
} from '@/service/tools/search-graph-inspector';
import { localWebSearchTool } from '@/service/tools/search-web';
import { Experimental_Agent as Agent, hasToolCall, stepCountIs } from 'ai';
import { genSystemInfo } from '@/service/tools/system-info';
import { PromptId } from '@/service/prompt/PromptId';
import { submitFinalAnswerTool } from '@/service/tools/submit-final-answer';
import { AgentTool, safeAgentTool } from '@/service/tools/types';
import { createUpdateResultTool, DEFAULT_COLOR, DEFAULT_ICON, DEFAULT_PLACEHOLDER, NO_MEANINGFUL_CONTENT_MESSAGE, UpdateResultToolConfig } from '@/service/tools/update-result-tool';
import { z } from 'zod/v3';
import { buildLLMRequestMessage, concatLLMRequestMessages } from '@/core/providers/helpers/message-helper';
import { AIServiceManager } from '../chat/service-manager';
import { sqliteStoreManager } from '@/core/storage/sqlite/SqliteStoreManager';
import { AppContext } from '@/app/context/AppContext';

export interface AISearchAgentOptions {
    enableWebSearch?: boolean;
    enableLocalSearch?: boolean;
    /**
     * Maximum iterations for multi-agent ReAct loop.
     */
    maxMultiAgentIterations?: number;
    /**
     * Maximum wall clock time in milliseconds for the entire search.
     */
    maxWallClockMs?: number;
    /**
     * model id for thought agent
     */
    thoughtAgentModel: string;
    /**
     * provider for thought agent
     */
    thoughtAgentProvider: string;
    /**
     * model id for search agent
     */
    searchAgentModel: string;
    /**
     * provider for search agent
     */
    searchAgentProvider: string;
}

/**
 * Tool set for thought agent (coordinator).
 */
type ThoughtToolSet = {
    call_search_agent: AgentTool;
    update_result: AgentTool;
    submit_final_answer: AgentTool;
};

/**
 * Tool set for search agent (executor)
 */
type SearchToolSet = {
    content_reader: AgentTool;
    web_search?: AgentTool;
    inspect_note_context?: AgentTool;
    graph_traversal?: AgentTool;
    find_path?: AgentTool;
    find_key_nodes?: AgentTool;
    find_orphans?: AgentTool;
    search_by_dimensions?: AgentTool;
    explore_folder?: AgentTool;
    recent_changes_whole_vault?: AgentTool;
    local_search_whole_vault?: AgentTool;
    submit_final_answer: AgentTool;
};

const DEFAULT_MAX_RECENT_MESSAGES = 10;
const DEFAULT_SUMMARY_UPDATE_THRESHOLD = 5;

// search agent max multi agent iterations.
const DEFAULT_MAX_MULTI_AGENT_ITERATIONS = 100;
// search thought agent max wall clock time.
const DEFAULT_MAX_WALL_CLOCK_MS = 10 * 60 * 1000;
// Maximum consecutive iterations without progress before forcing synthesis.
// IMPORTANT: this must be conservative, otherwise the agent may terminate before any meaningful tool chain completes.
const MAX_NO_PROGRESS_ITERATIONS = 4;
// Do not apply "no progress" early-stop too early, especially when the dashboard is still empty.
const MIN_ITERATIONS_BEFORE_NO_PROGRESS_CHECK = 10;
// search inspector agent max steps.
const DEFAULT_MAX_SEARCH_AGENT_STEPS = 50;

export interface InsightCard {
    id: string;
    title: string;
    description: string;
    icon: string;
    color: string;
}

export interface Suggestion {
    id: string;
    title: string;
    description: string;
    icon: string;
    color: string;
}

export interface AISearchSource {
    id: string;
    title: string;
    // important: we will open file by this path.
    path: string;
    // why it was selected or rejected.
    reasoning: string;
    // add badges to the item to quickly judge the role of each note in the current analysis.
    badges: string[];
    score: {
        // 0~100
        physical: number;
        semantic: number;
        average: number;
    }
}

export interface AISearchTopic {
    label: string;
    weight: number
}

export interface AISearchNode {
    // uuid of the node. generated by agent.
    id: string;
    // we can add many types of nodes. like file, folder, concept, tag, etc. determined by Agent.
    type: string;
    // title of the node. generated by agent.
    title: string;
    // important: we will open file by this path.
    path?: string;
    // attributes of the node. like tags, categories, etc. determined by Agent.
    attributes: {
        [key: string]: any;
    };
}

export interface AISearchEdge {
    // uuid of the edge. generated by agent.
    id: string;
    // uuid of the source node.
    source: string;
    // type of the edge. like link, reference, etc. determined by Agent.
    type: string;
    // uuid of the target node.
    target: string;
    // attributes of the edge. like weight, etc. determined by Agent.
    attributes: {
        [key: string]: any;
    };
}

export interface AISearchGraph {
    nodes: AISearchNode[];
    edges: AISearchEdge[];
}

export interface SearchAgentResult {
    summary: string;
    graph: AISearchGraph;
    insightCards?: InsightCard[];
    suggestions?: Suggestion[];
    topics: AISearchTopic[];
    sources: AISearchSource[];
}

export interface AgentMemory {
    /**
     * the original prompt from user
     */
    initialPrompt: string;
    /**
     * all messages in the session
     * messages includes tool calls and results.
     * actually. these will include the discovered_key_nodes, rejected_nodes, etc. so we don't need to store them separately.
     */
    historyMessages: LLMRequestMessage[];
    /**
     * summary of the session for 0~n messages due to the context window of the model
     */
    sessionSummary: string;
    /**
     * index of the last summary
     */
    lastSummaryIndex: number;
    /**
     * latest messages in the session
     */
    latestMessages: LLMRequestMessage[];
    /**
     * current query from user and assistant intermediate calls
     */
    currentQuery: string;
    /**
     * total token usage for the session
     */
    totalTokenUsage: LLMUsage;
}

/**
 * Search Agent.
 * ReAct architecture.
 * Multi agent architecture. (SubAgents)
 */
export class AISearchAgent {
    /**
     * Thought Agent - main coordinator for ReAct loop
     */
    private thoughtAgent: Agent<ThoughtToolSet>;

    /**
     * Search Agent - sub agent for search tasks
     */
    private searchAgent: Agent<SearchToolSet>;

    /**
     * Maximum iterations for multi-agent ReAct loop
     */
    private maxIterations: number;
    /**
     * Maximum wall clock time for the entire search
     */
    private maxWallClockMs: number;

    /**
     * Agent memory
     */
    private agentMemory: AgentMemory;
    /**
     * Agent result
     */
    private agentResult: SearchAgentResult;
    /**
     * Set of verified paths (paths that exist in vault/DB or appeared in tool outputs)
     */
    private verifiedPaths: Set<string> = new Set();

    constructor(
        private readonly aiServiceManager: AIServiceManager,
        private options: AISearchAgentOptions,
    ) {
        this.maxIterations = this.options.maxMultiAgentIterations ?? DEFAULT_MAX_MULTI_AGENT_ITERATIONS;
        this.maxWallClockMs = this.options.maxWallClockMs ?? DEFAULT_MAX_WALL_CLOCK_MS;

        // Create search agent (focused on search tasks, no submit_final_answer)
        let searchTools: SearchToolSet = {
            content_reader: contentReaderTool(),
            submit_final_answer: submitFinalAnswerTool(),
        };
        // todo
        // if (this.options.enableWebSearch) {
        //     searchTools.web_search = localWebSearchTool();
        // }
        if (this.options.enableLocalSearch) {
            searchTools.inspect_note_context = inspectNoteContextTool();
            searchTools.graph_traversal = graphTraversalTool();
            searchTools.find_path = findPathTool();
            searchTools.find_key_nodes = findKeyNodesTool();
            searchTools.find_orphans = findOrphansTool();
            searchTools.search_by_dimensions = searchByDimensionsTool();
            searchTools.explore_folder = exploreFolderTool();
            searchTools.recent_changes_whole_vault = recentChangesWholeVaultTool();
            searchTools.local_search_whole_vault = localSearchWholeVaultTool();
        }
        this.searchAgent = new Agent<SearchToolSet>({
            model: this.aiServiceManager.getMultiChat()
                .getProviderService(this.options.searchAgentProvider)
                .modelClient(this.options.searchAgentModel),
            tools: searchTools,
            stopWhen: [
                stepCountIs(DEFAULT_MAX_SEARCH_AGENT_STEPS),
                // stop when the submit_final_answer tool is called
                hasToolCall('submit_final_answer'),
            ],
        });

        // Create thought agent (main coordinator)
        const thoughtTools: ThoughtToolSet = {
            call_search_agent: this.callSearchAgentTool(),
            update_result: this.updateAgentResultTool(),
            submit_final_answer: submitFinalAnswerTool(),
        };
        this.thoughtAgent = new Agent<ThoughtToolSet>({
            model: this.aiServiceManager.getMultiChat()
                .getProviderService(this.options.thoughtAgentProvider)
                .modelClient(this.options.thoughtAgentModel),
            tools: thoughtTools,
            stopWhen: [
                // default: stop at every call. we manually control the loop using ReAct loop.
                stepCountIs(1),
                // stop when the submit_final_answer tool is called
                hasToolCall('submit_final_answer'),
            ],
            // do not use tool choice. this only control the next tool to be called.
            // don't understand this too much currently. don't find enough documentation about it.
            // toolChoice: {
            //     type: 'tool',
            //     toolName: 'submit_final_answer',
            // },
        });
    }

    /**
     * Stream search execution (used internally by thought agent)
     */
    private async streamSearch(prompt: string): Promise<AsyncGenerator<LLMStreamEvent>> {
        if (!prompt) {
            return (async function* (): AsyncGenerator<LLMStreamEvent> {
                yield { type: 'error', error: new Error('search prompt is required') };
            })();
        }

        const system = await this.aiServiceManager.renderPrompt(
            PromptId.AiSearchSystem,
            await genSystemInfo()
        );
        // read and learn: https://gist.github.com/sshh12/25ad2e40529b269a88b80e7cf1c38084
        const result = this.searchAgent.stream({
            system: system,
            prompt,
        });

        const self = this;

        return (async function* (): AsyncGenerator<LLMStreamEvent> {
            let finalSummary: string = '';
            const reasoningTextChunks: string[] = [];
            const thoughtTextChunks: string[] = [];
            for await (const chunk of result.fullStream) {
                switch (chunk.type) {
                    case 'text-delta':
                        thoughtTextChunks.push(chunk.text);
                        yield { type: 'text-delta', text: chunk.text, triggerName: StreamTriggerName.SEARCH_INSPECTOR_AGENT };
                        break;
                    case 'reasoning-delta':
                        reasoningTextChunks.push(chunk.text);
                        yield { type: 'reasoning-delta', text: chunk.text, triggerName: StreamTriggerName.SEARCH_INSPECTOR_AGENT };
                        break;
                    case 'tool-call': {
                        if (chunk.toolName === 'submit_final_answer') {
                            finalSummary = chunk.input.summary;
                            break;
                        }
                        // Preserve toolCallId for UI correlation
                        const callId = (chunk as any).toolCallId ?? `search-${Date.now()}-${Math.random().toString(36).slice(2, 8)}`;
                        yield {
                            type: 'tool-call',
                            id: callId,
                            toolName: chunk.toolName,
                            input: chunk.input,
                            triggerName: StreamTriggerName.SEARCH_INSPECTOR_AGENT
                        };
                        break;
                    }
                    case 'tool-result': {
                        // Register verified paths from tool outputs (EvidenceGate)
                        self.registerVerifiedPathsFromToolOutput(chunk.toolName, chunk.output);
                        // Preserve toolCallId for UI correlation
                        const resultId = (chunk as any).toolCallId ?? `search-${Date.now()}-${Math.random().toString(36).slice(2, 8)}`;
                        yield {
                            type: 'tool-result',
                            id: resultId,
                            toolName: chunk.toolName,
                            input: chunk.input,
                            output: chunk.output,
                            triggerName: StreamTriggerName.SEARCH_INSPECTOR_AGENT
                        };
                        break;
                    }
                    case 'tool-error': {
                        const errMsg = typeof (chunk as any).error === 'string'
                            ? (chunk as any).error
                            : (chunk as any).error?.message ?? JSON.stringify((chunk as any).error);
                        const toolName = (chunk as any).toolName ?? 'unknown';
                        console.warn('[AISearchAgent][streamSearch] tool-error:', toolName, errMsg);

                        yield {
                            type: 'error',
                            error: new Error(`Tool ${toolName} failed: ${errMsg}`),
                            triggerName: StreamTriggerName.SEARCH_INSPECTOR_AGENT,
                            extra: { toolName, toolCallId: (chunk as any).toolCallId },
                        };
                        break;
                    }
                    case 'finish': {
                        // console.debug('[AISearchAgent][streamSearch] complete:', JSON.stringify({
                        //     summary: finalSummary,
                        //     text: thoughtTextChunks.join('').trim(),
                        //     reasoning: reasoningTextChunks.join('').trim(),
                        // }));
                        yield {
                            type: 'complete',
                            finishReason: chunk.finishReason,
                            usage: chunk.totalUsage,
                            triggerName: StreamTriggerName.SEARCH_INSPECTOR_AGENT,
                            result: {
                                summary: finalSummary,
                                text: thoughtTextChunks.join('').trim(),
                                reasoning: reasoningTextChunks.join('').trim(),
                            },
                        };
                        break;
                    }
                    case 'start':
                    case 'start-step':
                    case 'reasoning-start':
                    case 'reasoning-end':
                    case 'text-start':
                    case 'text-end':
                    case 'finish-step':
                    case 'tool-input-end':
                    case 'tool-input-start':
                    case 'tool-input-delta':
                        // devtools will merge these duplicate logs.
                        console.debug('[AISearchAgent] streamSearch skip. one of the following types: '
                            + 'start, start-step, reasoning-start, reasoning-end, text-start, text-end, '
                            + 'finish-step, tool-input-start, tool-input-delta, tool-input-end');
                        break;
                    default:
                        yield { type: 'unSupported', chunk: chunk, comeFrom: 'streamSearch', triggerName: StreamTriggerName.SEARCH_INSPECTOR_AGENT };
                        break;
                }
            }
        })();
    }

    /**
     * Execute the ReAct loop (ThoughtAgent coordinates SearchAgent)
     * Implements controlled state machine with early stop and time budget.
     */
    private async *executeReActLoop(initialPrompt: string): AsyncGenerator<LLMStreamEvent> {
        // Initialize agent memory for this session
        this.agentMemory = {
            initialPrompt,
            sessionSummary: '',
            historyMessages: [buildLLMRequestMessage('user', initialPrompt)],
            latestMessages: [buildLLMRequestMessage('user', initialPrompt)],
            currentQuery: initialPrompt,
            lastSummaryIndex: 0,
            totalTokenUsage: {
                inputTokens: 0,
                outputTokens: 0,
                totalTokens: 0,
            }
        };

        // iteraction control
        let iterationCount = 0;
        let reActStartTimeMs = Date.now();
        let isSubmitResultCalled = false;
        // Track progress for early stop detection
        let noProgressIterations = 0;
        let previousSourcesCount = 0;
        let previousNodesCount = 0;
        let previousEdgesCount = 0;

        while (iterationCount < this.maxIterations) {
            iterationCount++;

            // Check time budget before starting new iteration
            const elapsedMs = Date.now() - reActStartTimeMs;
            if (elapsedMs > this.maxWallClockMs) {
                yield {
                    type: 'pk-debug',
                    debugName: 'thought-agent-time-budget-exceeded',
                    triggerName: StreamTriggerName.SEARCH_THOUGHT_AGENT,
                    extra: {
                        reason: `[AISearchAgent] Time budget exceeded (${elapsedMs}ms > ${this.maxWallClockMs}ms), forcing synthesis`,
                    },
                };
                break;
            }

            // Check early stop conditions
            const currentSourcesCount = this.agentResult.sources.length;
            const currentNodesCount = this.agentResult.graph.nodes.length;
            const currentEdgesCount = this.agentResult.graph.edges.length;
            yield {
                type: 'pk-debug',
                debugName: 'thought-agent-iteration-progress',
                triggerName: StreamTriggerName.SEARCH_THOUGHT_AGENT,
                extra: {
                    iterationCount,
                    currentSourcesCount,
                    currentNodesCount,
                    currentEdgesCount,
                    previousSourcesCount,
                    previousNodesCount,
                    previousEdgesCount,
                    noProgressIterations,
                },
            };
            // Detect no progress - force synthesis only after we gave the agent enough iterations to actually run tool chains.
            if (iterationCount >= MIN_ITERATIONS_BEFORE_NO_PROGRESS_CHECK) {
                if (currentSourcesCount === previousSourcesCount &&
                    currentNodesCount === previousNodesCount &&
                    currentEdgesCount === previousEdgesCount) {
                    noProgressIterations++;
                } else {
                    noProgressIterations = 0;
                }
            }
            if (noProgressIterations >= MAX_NO_PROGRESS_ITERATIONS) {
                yield {
                    type: 'pk-debug',
                    debugName: 'thought-agent-no-progress',
                    triggerName: StreamTriggerName.SEARCH_THOUGHT_AGENT,
                    extra: {
                        reason: `[AISearchAgent] No progress for ${noProgressIterations} iterations (sources=${currentSourcesCount}), forcing synthesis`,
                    },
                };
                break;
            }
            previousSourcesCount = currentSourcesCount;
            previousNodesCount = currentNodesCount;
            previousEdgesCount = currentEdgesCount;

            const thoughtTextChunks: string[] = [];
            const reasoningTextChunks: string[] = [];
            let stepTokenUsage: LLMUsage = {
                inputTokens: 0,
                outputTokens: 0,
                totalTokens: 0,
            };
            let toolCalls: Array<{ toolCallId: string; toolName: string; input: any }> = [];
            let toolResults: Array<{ toolCallId: string; toolName: string; output: ToolResultOutput }> = [];

            // Build current prompt with agent memory, yielding progress events
            const promptGenerator = this.buildCurrentPrompt();
            for await (const chunk of promptGenerator) {
                // Yield summary generation progress
                yield chunk;
            }
            // Get the final prompt after summarization is complete
            const currentPrompt = this.agentMemoryToPrompt();
            const nextThoughtPrompt = toReActThoughtPromptMessages(currentPrompt);
            yield {
                type: 'pk-debug',
                debugName: 'thought-agent-next-thought-prompt',
                triggerName: StreamTriggerName.SEARCH_THOUGHT_AGENT,
                extra: {
                    nextThoughtPrompt,
                },
            };

            // ThoughtAgent thinks and decides next action (streaming)
            const thoughtStream = this.thoughtAgent.stream({
                system: await this.aiServiceManager.renderPrompt(PromptId.ThoughtAgentSystem, {}),
                prompt: nextThoughtPrompt,
            });
            // Process thoughtAgent's stream in real-time
            for await (const chunk of thoughtStream.fullStream) {
                switch (chunk.type) {
                    case 'text-delta':
                        thoughtTextChunks.push(chunk.text);
                        yield { type: 'text-delta', text: chunk.text, triggerName: StreamTriggerName.SEARCH_THOUGHT_AGENT };
                        break;
                    case 'reasoning-delta':
                        reasoningTextChunks.push(chunk.text);
                        yield { type: 'reasoning-delta', text: chunk.text, triggerName: StreamTriggerName.SEARCH_THOUGHT_AGENT };
                        break;
                    case 'tool-call': {
                        const toolCallId = (chunk as { toolCallId?: string }).toolCallId ?? generateToolCallId();
                        toolCalls.push({ toolCallId, toolName: chunk.toolName, input: chunk.input });
                        if (chunk.toolName === 'submit_final_answer') {
                            isSubmitResultCalled = true;
                        }
                        yield {
                            type: 'tool-call',
                            id: toolCallId,
                            toolName: chunk.toolName,
                            input: chunk.input,
                            triggerName: StreamTriggerName.SEARCH_THOUGHT_AGENT,
                        };

                        // Handle search agent call immediately to get streaming output
                        if (chunk.toolName === 'call_search_agent') {
                            const searchPrompt = (chunk.input?.prompt ?? chunk.input?.query) ?? '';
                            const searchStream = await this.streamSearch(searchPrompt);

                            // Forward search agent output in real-time
                            const searchResultChunks: Record<string, any> = {};
                            for await (const searchChunk of searchStream) {
                                switch (searchChunk.type) {
                                    case 'complete':
                                        stepTokenUsage = this.mergeTokenUsage(stepTokenUsage, searchChunk.usage);
                                        searchResultChunks.summary = searchChunk.result?.summary?.trim?.()?.length
                                            ? searchChunk.result.summary
                                            : searchChunk.result?.text;
                                        break;
                                    default:
                                        yield searchChunk;
                                        break;
                                }
                            }

                            toolResults.push({
                                toolCallId,
                                toolName: 'call_search_agent',
                                output: {
                                    type: 'text',
                                    value: JSON.stringify(searchResultChunks),
                                }
                            });
                            yield {
                                type: 'tool-result',
                                id: toolCallId,
                                toolName: 'call_search_agent',
                                input: chunk.input,
                                output: searchResultChunks,
                                triggerName: StreamTriggerName.SEARCH_THOUGHT_AGENT
                            };
                        }
                        break;
                    }
                    case 'tool-result':
                        // already handled by call_search_agent tool-result.
                        if (chunk.toolName === 'call_search_agent') {
                            break;
                        }
                        // Register verified paths from tool outputs (EvidenceGate)
                        this.registerVerifiedPathsFromToolOutput(chunk.toolName, chunk.output);

                        const toolCallId = (chunk as { toolCallId?: string }).toolCallId ?? generateToolCallId();
                        toolResults.push({
                            toolCallId,
                            toolName: chunk.toolName,
                            output: {
                                type: 'text',
                                value: JSON.stringify(chunk.output),
                            }
                        });
                        yield {
                            type: 'tool-result',
                            id: toolCallId,
                            toolName: chunk.toolName,
                            input: chunk.input,
                            output: chunk.output,
                            triggerName: StreamTriggerName.SEARCH_THOUGHT_AGENT,
                            extra: {
                                currentResult: this.agentResult,
                            },
                        };
                        break;
                    case 'finish':
                        stepTokenUsage = this.mergeTokenUsage(stepTokenUsage, chunk.totalUsage);
                        yield {
                            type: 'on-step-finish',
                            text: thoughtTextChunks.join('').trim(),
                            finishReason: chunk.finishReason,
                            usage: chunk.totalUsage,
                            triggerName: StreamTriggerName.SEARCH_THOUGHT_AGENT
                        };
                        break;
                    case 'tool-error': {
                        const errMsg = typeof (chunk as any).error === 'string'
                            ? (chunk as any).error
                            : (chunk as any).error?.message ?? JSON.stringify((chunk as any).error);
                        const toolName = (chunk as any).toolName ?? 'unknown';

                        const isRecoverableError = errMsg.includes('unavailable tool') || errMsg.includes('not available') || errMsg.includes('Available tools:');

                        // All errors must be yield as error. but recoverable errors will be handled separately.
                        yield {
                            type: 'error',
                            error: new Error(`Tool ${toolName} failed: ${errMsg}`),
                            triggerName: StreamTriggerName.SEARCH_THOUGHT_AGENT,
                            extra: { toolName, toolCallId: (chunk as any).toolCallId, isRecoverableError },
                        };

                        // Recoverable error: "unavailable tool" - ThoughtAgent tried to call SearchAgent's tools directly
                        if (isRecoverableError) {
                            // Inject corrective reminder into agent memory for next iteration
                            const correctiveMessage = buildLLMRequestMessage('assistant',
                                `Error: Attempted to call unavailable tool '${toolName}'. ` +
                                `ThoughtAgent can only use: ${Object.keys(this.thoughtAgent.tools).join(', ')}. ` +
                                `To search the vault, use call_search_agent with a prompt describing what you want to find.`
                            );
                            this.agentMemory.latestMessages.push(correctiveMessage);
                            break;
                        }

                        break;
                    }
                    case 'start':
                    case 'start-step':
                    case 'reasoning-start':
                    case 'reasoning-end':
                    case 'text-start':
                    case 'text-end':
                    case 'finish-step':
                    case 'tool-input-start':
                    case 'tool-input-delta':
                    case 'tool-input-end':
                        // devtools will merge these duplicate logs.
                        console.debug('[AISearchAgent] thoughtAgent skip. one of the following types: '
                            + 'start, start-step, reasoning-start, reasoning-end, text-start, text-end, '
                            + 'finish-step, tool-input-start, tool-input-delta, tool-input-end');
                        break;
                    default:
                        yield { type: 'unSupported', chunk: chunk, comeFrom: 'thoughtAgent', triggerName: StreamTriggerName.SEARCH_THOUGHT_AGENT };
                        break;
                }
            }

            // Build thought message and update agent memory
            this.buildIterationThoughtMessage(thoughtTextChunks, reasoningTextChunks, toolCalls, toolResults, stepTokenUsage);

            // ThoughtAgent decided to submit final answer, end the loop
            if (isSubmitResultCalled) {
                console.debug('[AISearchAgent] ThoughtAgent decided to submit final answer, end the loop');
                break;
            }
        }

        if (!isSubmitResultCalled) {
            yield {
                type: 'pk-debug',
                debugName: 'Exited_loop_without_submitting',
                extra: {
                    messages: 'Exited loop without submitting (max iterations or early stop)',
                    reActStartTimeMs,
                    reActEndTimeMs: Date.now(),
                    reActDurationMs: Date.now() - reActStartTimeMs,
                },
            }
        }
        yield* this.finishReActLoop(reActStartTimeMs);
    }

    private async *finishReActLoop(reActStartTimeMs: number): AsyncGenerator<LLMStreamEvent> {
        for await (const chunk of this.streamFinalSummary()) {
            yield chunk;
        }

        yield {
            type: 'complete',
            finishReason: 'stop',
            usage: this.agentMemory.totalTokenUsage,
            durationMs: Date.now() - reActStartTimeMs,
            result: this.agentResult,
            triggerName: StreamTriggerName.SEARCH_THOUGHT_AGENT,
        };
    }

    private buildIterationThoughtMessage(
        thoughtTextChunks: string[], reasoningTextChunks: string[],
        toolCalls: { toolCallId: string; toolName: string; input: any }[],
        toolResults: { toolCallId: string; toolName: string; output: any }[],
        stepTokenUsage: LLMUsage
    ): LLMRequestMessage {
        const thoughtText = thoughtTextChunks.join('');
        const reasoningText = reasoningTextChunks.join('');
        const thoughtMessage: LLMRequestMessage = {
            role: 'assistant',
            content: []
        }
        if (thoughtText.trim().length > 0) {
            thoughtMessage.content.push({ type: 'text', text: thoughtText.trim() });
        }
        if (reasoningText.trim().length > 0) {
            thoughtMessage.content.push({ type: 'reasoning', text: reasoningText.trim() });
        }
        if (toolCalls.length > 0) {
            thoughtMessage.content.push(
                ...toolCalls.map(({ toolCallId, toolName, input }) => ({
                    type: 'tool-call' as const,
                    toolCallId,
                    toolName,
                    input
                }))
            );
        }
        if (toolResults.length > 0) {
            thoughtMessage.content.push(
                ...toolResults.map(({ toolCallId, toolName, output }) => ({
                    type: 'tool-result' as const,
                    toolCallId,
                    toolName,
                    output
                }))
            );
        }
        this.agentMemory.historyMessages.push(thoughtMessage);
        this.agentMemory.latestMessages.push(thoughtMessage);
        this.agentMemory.totalTokenUsage = this.mergeTokenUsage(this.agentMemory.totalTokenUsage, stepTokenUsage);
        return thoughtMessage;
    }

    /**
     * Stream the final summary prompt and set `agentResult.summary`.
     */
    private async *streamFinalSummary(): AsyncGenerator<LLMStreamEvent> {
        const variables = {
            agentResult: this.agentResult,
            agentMemory: this.agentMemory,
            options: this.options,
            latestMessagesText: convertMessagesToText(this.agentMemory.latestMessages),
        };

        const summaryStream = this.aiServiceManager.chatWithPromptStream(
            PromptId.SearchAiSummary,
            variables,
        );

        for await (const chunk of summaryStream) {
            if (chunk.type === 'prompt-stream-result') {
                this.agentResult.summary = chunk.output;
            }
            yield { ...chunk, triggerName: StreamTriggerName.SEARCH_THOUGHT_AGENT };
        }
    }

    private mergeTokenUsage(usage1: LLMUsage, usage2: LLMUsage): LLMUsage {
        return {
            inputTokens: (usage1.inputTokens ?? 0) + (usage2.inputTokens ?? 0) || undefined,
            outputTokens: (usage1.outputTokens ?? 0) + (usage2.outputTokens ?? 0) || undefined,
            totalTokens: (usage1.totalTokens ?? 0) + (usage2.totalTokens ?? 0) || undefined,
            reasoningTokens: (usage1.reasoningTokens ?? 0) + (usage2.reasoningTokens ?? 0) || undefined,
            cachedInputTokens: (usage1.cachedInputTokens ?? 0) + (usage2.cachedInputTokens ?? 0) || undefined,
        };
    }

    /**
     * Check if current conversation context exceeds token limits and needs summarization
     */
    private async shouldSummarizeHistory(): Promise<{ shouldSummarize: boolean, reason?: string }> {
        const history = this.agentMemory.historyMessages;
        if (history.length <= DEFAULT_SUMMARY_UPDATE_THRESHOLD) {
            return {
                shouldSummarize: false,
                reason: `history length(${history.length}) is less than or equal to ${DEFAULT_SUMMARY_UPDATE_THRESHOLD}`
            };
        }

        const tokenLimits = await this.aiServiceManager.getModelTokenLimits(
            this.options.thoughtAgentModel,
            this.options.thoughtAgentProvider
        );
        if (!tokenLimits) {
            const shouldSummarize = history.length - this.agentMemory.lastSummaryIndex > DEFAULT_SUMMARY_UPDATE_THRESHOLD;
            // Fall back to message count based logic if token limits are not available
            return {
                shouldSummarize,
                reason: `No available token limits. Fall back to message count based logic. history length(${history.length}) - lastSummaryIndex(${this.agentMemory.lastSummaryIndex}) > ${DEFAULT_SUMMARY_UPDATE_THRESHOLD}`
            };
        }

        // Use recommended summary threshold or 80% of max tokens as default
        const summaryThreshold = tokenLimits.recommendedSummaryThreshold ??
            (tokenLimits.maxInputTokens ? Math.floor(tokenLimits.maxInputTokens * 0.8) :
                (tokenLimits.maxTokens ? Math.floor(tokenLimits.maxTokens * 0.8) : 0));

        if (summaryThreshold <= 0) {
            // Fall back to message count based logic
            const shouldSummarize = history.length - this.agentMemory.lastSummaryIndex > DEFAULT_SUMMARY_UPDATE_THRESHOLD;
            return {
                shouldSummarize,
                reason: `Summary threshold is less than or equal to 0. Fall back to message count based logic. history length(${history.length}) - lastSummaryIndex(${this.agentMemory.lastSummaryIndex}) > ${DEFAULT_SUMMARY_UPDATE_THRESHOLD}`
            };
        }

        // Estimate tokens for recent messages since last summary
        const recentMessages = history.slice(this.agentMemory.lastSummaryIndex);
        const estimatedTokens = this.aiServiceManager.estimateTokens(
            recentMessages
        );

        return {
            shouldSummarize: estimatedTokens > summaryThreshold,
            reason: `Token estimation: ${estimatedTokens} tokens, threshold: ${summaryThreshold}`
        };
    }

    /**
     * Build current prompt with agent memory, yielding progress events during summarization
     */
    private async *buildCurrentPrompt(): AsyncGenerator<LLMStreamEvent> {
        // Check if summarization is needed based on token limits
        const { shouldSummarize, reason } = await this.shouldSummarizeHistory();
        if (!shouldSummarize) {
            return;
        }

        // Calculate which messages need to be summarized
        const history = this.agentMemory.historyMessages;
        let messagesToSummarize: LLMRequestMessage[] = history.slice(0, -DEFAULT_SUMMARY_UPDATE_THRESHOLD)
        const messagesToSummarizeText = concatLLMRequestMessages(messagesToSummarize);

        // If history is long (based on token limits), do summarization
        const toolCallId = generateToolCallId();
        yield {
            type: 'tool-call',
            id: toolCallId,
            toolName: ToolEvent.summary_context_messages,
            triggerName: StreamTriggerName.SEARCH_THOUGHT_AGENT,
            input: {
                reason,
                messagesToSummarize: messagesToSummarizeText,
            },
        };

        // Generate summary immediately
        this.agentMemory.sessionSummary = await this.aiServiceManager.chatWithPrompt(PromptId.DocSummary, {
            content: messagesToSummarizeText,
            title: `Thought Agent History of the user query: \`${this.agentMemory.initialPrompt}\` `,
            wordCount: `less than ${AppContext.getInstance().settings.search.aiAnalysisSessionSummaryWordCount}`,
        });

        this.agentMemory.lastSummaryIndex = messagesToSummarize.length - 1;
        this.agentMemory.latestMessages = DEFAULT_MAX_RECENT_MESSAGES > this.agentMemory.historyMessages.length
            ? this.agentMemory.historyMessages
            : [...this.agentMemory.historyMessages.slice(-DEFAULT_MAX_RECENT_MESSAGES),];

        yield {
            type: 'tool-result',
            id: toolCallId,
            toolName: ToolEvent.summary_context_messages,
            triggerName: StreamTriggerName.SEARCH_THOUGHT_AGENT,
            input: {
                reason,
                messagesToSummarize: messagesToSummarizeText,
            },
            output: {
                type: 'text',
                value: this.agentMemory.sessionSummary,
            }
        };
    }

    /**
     * Convert agent memory to LLMRequestMessage array
     */
    private agentMemoryToPrompt(): LLMRequestMessage[] {
        if (this.agentMemory.sessionSummary && this.agentMemory.sessionSummary.trim().length > 0) {
            return [
                buildLLMRequestMessage('assistant', this.agentMemory.sessionSummary),
                ...this.agentMemory.latestMessages,
            ];
        }
        return this.agentMemory.latestMessages;
    }

    /**
     * Stream search results with ReAct loop (ThoughtAgent coordinates SearchAgent)
     */
    async stream(prompt: string): Promise<AsyncGenerator<LLMStreamEvent>> {
        this.resetAgentResult();
        return this.executeReActLoop(prompt);
    }

    private resetAgentResult(): SearchAgentResult {
        this.agentResult = {
            summary: '',
            topics: [],
            graph: { nodes: [], edges: [] },
            sources: [],
            insightCards: [],
            suggestions: [],
        };
        // Clear verified paths for fresh start
        this.verifiedPaths.clear();
        return this.agentResult;
    }

    /**
     * Tool for thought agent to call search agent
     */
    private callSearchAgentTool(): AgentTool {
        return safeAgentTool({
            description: "Execute a search task using the search agent. Provide a specific search prompt that focuses on gathering relevant information.",
            inputSchema: z.object({
                prompt: z.string().optional().describe("The search prompt for the search agent"),
                query: z.string().optional().describe("Alternative to prompt; same meaning"),
            }).refine((d) => !!(d.prompt ?? d.query), { message: "Either prompt or query is required" }),
            execute: async (params) => {
                const prompt = (params?.prompt ?? params?.query) ?? "";
                return { prompt };
            },
        });
    }

    /**
     * Update agent result with flexible operations
     */
    private updateAgentResultTool(): AgentTool {
        const config: UpdateResultToolConfig = {
            availableFields: [
                {
                    name: 'topics',
                    description: 'Array of key topics found during the search',
                    type: 'array'
                },
                {
                    name: 'sources',
                    description: 'Array of source documents with metadata, scoring, and reasoning',
                    type: 'array'
                },
                {
                    name: 'graph.nodes',
                    description: 'Knowledge graph nodes (files, concepts, tags, etc.)',
                    type: 'array'
                },
                {
                    name: 'graph.edges',
                    description: 'Relationships between nodes (links, references, etc.)',
                    type: 'array'
                },
                {
                    name: 'insightCards',
                    description: 'Actionable insights with icons and colors for quick recognition',
                    type: 'array'
                },
                {
                    name: 'suggestions',
                    description: 'Recommended next steps or related actions',
                    type: 'array'
                }
            ],
            itemSchemas: {
                topics: z.object({
                    label: z.string().default(DEFAULT_PLACEHOLDER),
                    weight: z.number().min(0).optional(),
                }).superRefine((data, ctx) => {
                    // if all fields are default values, discard the object
                    if ((!data.label || data.label === DEFAULT_PLACEHOLDER) &&
                        (data.weight === undefined)) {
                        ctx.addIssue({
                            code: z.ZodIssueCode.custom,
                            message: NO_MEANINGFUL_CONTENT_MESSAGE,
                        });
                    }
                }),
                sources: z.object({
                    id: z.string().default(() => `src:${Date.now()}-${Math.random().toString(36).slice(2, 8)}`),
                    title: z.string().default(DEFAULT_PLACEHOLDER),
                    path: z.string().describe('The actual file path (e.g., "folder/my-file.md"). DO NOT use placeholder values like "Untitled". Must be a valid file path that exists in the vault.').default(DEFAULT_PLACEHOLDER),
                    reasoning: z.string().default(DEFAULT_PLACEHOLDER),
                    badges: z.array(z.string()).default(() => []),
                    score: z.object({
                        physical: z.number().min(0).max(100).optional(),
                        semantic: z.number().min(0).max(100).optional(),
                        average: z.number().min(0).max(100).optional(),
                    }).optional(),
                }).superRefine((data, ctx) => {
                    // if key fields are default values, discard the object
                    if ((data.title === DEFAULT_PLACEHOLDER) &&
                        (!data.path || data.path === DEFAULT_PLACEHOLDER) &&
                        (!data.reasoning || data.reasoning === DEFAULT_PLACEHOLDER) &&
                        (!data.badges || data.badges.length === 0)) {
                        ctx.addIssue({
                            code: z.ZodIssueCode.custom,
                            message: NO_MEANINGFUL_CONTENT_MESSAGE,
                        });
                    }
                }),
                'graph.nodes': z.object({
                    id: z.string().optional().default(() => `node:${Date.now()}-${Math.random().toString(36).slice(2, 8)}`),
                    type: z.string().default('document'),
                    title: z.string().default(DEFAULT_PLACEHOLDER),
                    label: z.string().default(DEFAULT_PLACEHOLDER),
                    path: z.string().describe('For document/file nodes: provide the actual file path (e.g., "folder/my-file.md"). DO NOT use placeholder values like "Untitled". The path must be a valid file path that exists in the vault.').default(DEFAULT_PLACEHOLDER),
                    attributes: z.record(z.any()).default(() => ({})),
                }).superRefine((data, ctx) => {
                    if (data.title && !data.label) {
                        (data as any).label = data.title;
                    }
                    if (data.label && !data.title) {
                        (data as any).title = data.label;
                    }

                    // Ensure path is meaningful for file/document nodes
                    if (data.type === 'document' || data.type === 'file') {
                        if (!data.path || data.path === DEFAULT_PLACEHOLDER || data.path === 'Untitled') {
                            if (data.attributes?.path) {
                                data.path = data.attributes.path;
                            } else {
                                ctx.addIssue({
                                    code: z.ZodIssueCode.custom,
                                    message: "Document/file nodes must have a valid path. DO NOT use placeholder values like 'Untitled'. Provide the actual file path (e.g., 'folder/my-file.md').",
                                    path: ["path"]
                                });
                            }
                        }
                    }

                    // if key fields are default values, discard the object
                    if ((data.title === DEFAULT_PLACEHOLDER) &&
                        (data.label === DEFAULT_PLACEHOLDER) &&
                        (!data.path || data.path === DEFAULT_PLACEHOLDER) &&
                        (!data.attributes || Object.keys(data.attributes).length === 0)) {
                        ctx.addIssue({
                            code: z.ZodIssueCode.custom,
                            message: NO_MEANINGFUL_CONTENT_MESSAGE,
                        });
                    }
                }),
                'graph.edges': z.object({
                    id: z.string().default(() => `edge:${Date.now()}-${Math.random().toString(36).slice(2, 8)}`),
                    source: z.string(),
                    type: z.string().default('link'),
                    target: z.string(),
                    label: z.string().default(''),
                    attributes: z.record(z.any()).default(() => ({})),
                }).refine((data) => data.source && data.target, {
                    message: "source and target are required",
                    path: ["source"]
                }).refine((data) => data.source !== data.target, {
                    message: "source and target cannot be the same",
                    path: ["source"]
                }),
                insightCards: z.object({
                    id: z.string().default(() => `card:${Date.now()}-${Math.random().toString(36).slice(2, 8)}`),
                    title: z.string().default(DEFAULT_PLACEHOLDER),
                    description: z.string().default(DEFAULT_PLACEHOLDER),
                    content: z.string().default(DEFAULT_PLACEHOLDER),
                    icon: z.string().default(DEFAULT_ICON),
                    color: z.string().default(DEFAULT_COLOR),
                }).superRefine((data, ctx) => {
                    if (data.content && !data.description) {
                        (data as any).description = data.content;
                    }

                    if ((data.title === DEFAULT_PLACEHOLDER || !data.title) &&
                        (data.description === DEFAULT_PLACEHOLDER || data.description === DEFAULT_PLACEHOLDER || !data.description)) {
                        ctx.addIssue({
                            code: z.ZodIssueCode.custom,
                            message: NO_MEANINGFUL_CONTENT_MESSAGE,
                        });
                    }
                }),
                suggestions: z.object({
                    id: z.string().default(() => `suggestion:${Date.now()}-${Math.random().toString(36).slice(2, 8)}`),
                    title: z.string().default(DEFAULT_PLACEHOLDER),
                    description: z.string().default(DEFAULT_PLACEHOLDER),
                    icon: z.string().default(DEFAULT_ICON),
                    color: z.string().default(DEFAULT_COLOR),
                }).superRefine((data, ctx) => {
                    // if key fields are default values, discard the object
                    if ((data.title === DEFAULT_PLACEHOLDER || !data.title) &&
                        (data.description === DEFAULT_PLACEHOLDER || data.description === DEFAULT_PLACEHOLDER || !data.description)) {
                        ctx.addIssue({
                            code: z.ZodIssueCode.custom,
                            message: NO_MEANINGFUL_CONTENT_MESSAGE,
                        });
                    }
                })
            },
            descriptionExtra: 'CRITICAL: When adding graph nodes or sources, ALWAYS provide valid file paths. DO NOT use placeholder values like "Untitled" for paths - they must be actual file paths that exist in the vault (e.g., "folder/my-file.md"). Invalid paths will be rejected.',
            examples: [
                'Add topic: {"operations": [{"operation": "add", "targetField": "topics", "item": {"label": "topic1", "weight": 1}}]}',
                'Add source: {"operations": [{"operation": "add", "targetField": "sources", "item": {"id": "src:file.md", "title": "Title", "path": "file.md", "reasoning": "reason", "badges": ["tag"], "score": {"physical": 80, "semantic": 90, "average": 85}}}]}',
                'Add graph node: {"operations": [{"operation": "add", "targetField": "graph.nodes", "item": {"type": "document", "title": "My Document", "label": "My Document", "path": "folder/my-document.md", "attributes": {}}}]} (IMPORTANT: path must be actual file path, never use "Untitled" or placeholders)',
                'Remove item: {"operations": [{"operation": "remove", "targetField": "sources", "removeId": "src:file.md"}]}',
                'Multiple operations: {"operations": [{"operation": "add", "targetField": "topics", "item": {"label": "AI", "weight": 1}}, {"operation": "add", "targetField": "insightCards", "item": {"id": "card1", "title": "Key Finding", "description": "Found important insights", "icon": "bulb", "color": "yellow"}}]}'
            ],
            result: () => this.agentResult || this.resetAgentResult(), // Dynamic result getter
            validatePath: (path: string) => this.validatePath(path),
            verifiedPaths: this.verifiedPaths
        };

        const baseTool = createUpdateResultTool(config);

        // Wrap the tool to add graph consistency validation
        return {
            ...baseTool,
            execute: async (input: any) => {
                // Execute the original tool
                const result = await baseTool.execute(input);

                // Check graph consistency after updates
                const graphValidation = this.validateGraphConsistency();
                if (!graphValidation.isValid) {
                    console.warn('[AISearchAgent] Graph consistency issues detected:', graphValidation.issues);

                    // Create a corrective message for the AI
                    const correctiveMessage = ` GRAPH CONSISTENCY ISSUES DETECTED:\n${graphValidation.issues.join('\n')}\n\nPlease fix these issues by:\n1. Remove invalid edges using: {"operations": [{"operation": "remove", "targetField": "graph.edges", "removeId": "edge-id"}]}"\n2. Add missing nodes using: {"operations": [{"operation": "add", "targetField": "graph.nodes", "item": {...}}]}\n3. Ensure all edges reference existing nodes\n\nTool execution result: ${result}`;

                    // Inject corrective reminder into agent memory for next iteration
                    const correctiveSystemMessage = buildLLMRequestMessage('assistant',
                        `SYSTEM: Graph data consistency check failed. Issues: ${graphValidation.issues.join('; ')}. You must fix these issues before proceeding.`
                    );
                    this.agentMemory.latestMessages.push(correctiveSystemMessage);

                    return correctiveMessage;
                }

                return result;
            }
        };
    }

    /**
     * Validate that a path exists in the vault/DB or was seen in tool outputs.
     * This is the core of EvidenceGate - preventing hallucinated paths.
     */
    private async validatePath(path: string): Promise<{ valid: boolean; reason?: string }> {
        // Check if path was already verified (appeared in tool outputs)
        if (this.verifiedPaths.has(path)) {
            return { valid: true };
        }

        // Check if path exists in DB
        try {
            const docMetaRepo = sqliteStoreManager.getDocMetaRepo();
            const docMeta = await docMetaRepo.getByPath(path);
            if (docMeta) {
                this.verifiedPaths.add(path);
                return { valid: true };
            }
        } catch (error) {
            console.warn(`[AISearchAgent] Error checking path in DB: ${error}`);
        }

        // Check if file exists in vault
        try {
            const app = AppContext.getInstance().app;
            const file = app.vault.getAbstractFileByPath(path);
            if (file) {
                this.verifiedPaths.add(path);
                return { valid: true };
            }
        } catch (error) {
            console.warn(`[AISearchAgent] Error checking path in vault: ${error}`);
        }

        return {
            valid: false,
            reason: 'Path not found in vault or database. Only use paths from tool outputs (local_search_whole_vault, graph_traversal, etc.)'
        };
    }

    /**
     * Validate graph data consistency and return issues that need to be fixed
     */
    private validateGraphConsistency(): { isValid: boolean; issues: string[] } {
        const issues: string[] = [];
        const nodes = this.agentResult.graph.nodes;
        const edges = this.agentResult.graph.edges;

        // Create a set of valid node IDs for quick lookup
        const nodeIds = new Set(nodes.map(node => node.id));

        // Check for edges that reference non-existent nodes
        const invalidEdges = edges.filter(edge => {
            const sourceExists = nodeIds.has(edge.source);
            const targetExists = nodeIds.has(edge.target);

            if (!sourceExists) {
                issues.push(`Edge references non-existent source node: "${edge.source}"`);
            }
            if (!targetExists) {
                issues.push(`Edge references non-existent target node: "${edge.target}"`);
            }

            return !sourceExists || !targetExists;
        });

        // Check for orphaned edges
        if (invalidEdges.length > 0) {
            issues.push(`Found ${invalidEdges.length} edges referencing non-existent nodes`);
        }

        // Check for duplicate edges (same source and target)
        const edgeSignatures = new Set<string>();
        const duplicateEdges: string[] = [];
        edges.forEach(edge => {
            const signature = `${edge.source}::${edge.target}`;
            if (edgeSignatures.has(signature)) {
                duplicateEdges.push(signature);
            } else {
                edgeSignatures.add(signature);
            }
        });

        if (duplicateEdges.length > 0) {
            issues.push(`Found duplicate edges: ${duplicateEdges.join(', ')}`);
        }

        // Check for nodes with no meaningful content
        const emptyNodes = nodes.filter(node =>
            !node.title?.trim() ||
            node.title === 'Untitled' ||
            node.title.length < 2
        );

        if (emptyNodes.length > 0) {
            issues.push(`Found ${emptyNodes.length} nodes with empty or meaningless titles`);
        }

        // Check for isolated nodes (nodes with no edges)
        const connectedNodeIds = new Set<string>();
        edges.forEach(edge => {
            connectedNodeIds.add(edge.source);
            connectedNodeIds.add(edge.target);
        });

        const isolatedNodes = nodes.filter(node => !connectedNodeIds.has(node.id));
        if (isolatedNodes.length > 5) { // Allow some isolated nodes but warn if too many
            issues.push(`Found ${isolatedNodes.length} isolated nodes (nodes with no connections)`);
        }

        return {
            isValid: issues.length === 0,
            issues
        };
    }

    /**
     * Register paths from tool outputs as verified.
     * Called when processing vault_inspector or content_reader results.
     */
    private registerVerifiedPathsFromToolOutput(toolName: string, output: any): void {
        if (!output) return;

        try {
            // Handle structured output with results array (local_search, etc.)
            if (output.results && Array.isArray(output.results)) {
                for (const item of output.results) {
                    if (item.path) {
                        this.verifiedPaths.add(item.path);
                    }
                }
            }
            // Handle data.results pattern (hybrid mode)
            if (output.data?.results && Array.isArray(output.data.results)) {
                for (const item of output.data.results) {
                    if (item.path) {
                        this.verifiedPaths.add(item.path);
                    }
                }
            }
            // Handle graph nodes
            if (output.levels && Array.isArray(output.levels)) {
                for (const level of output.levels) {
                    if (level.documentNodes && Array.isArray(level.documentNodes)) {
                        for (const node of level.documentNodes) {
                            // Graph nodes may have path in attributes
                            const attrs = typeof node.attributes === 'string'
                                ? JSON.parse(node.attributes)
                                : node.attributes;
                            if (attrs?.path) {
                                this.verifiedPaths.add(attrs.path);
                            }
                        }
                    }
                }
            }
            // Handle content_reader responses
            if (toolName === 'content_reader' && typeof output === 'object' && output.path) {
                this.verifiedPaths.add(output.path);
            }
        } catch (error) {
            console.warn(`[AISearchAgent] Error extracting paths from tool output: ${error}`);
        }
    }

}